{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4: Realtime Data using ZIGSim (Workshop)\n",
    "\n",
    "This session will cover how to use realtime data from mobile sensors as inputs for training. Also, it will cover how to save and load datasets that can be useful when data are collected offline.\n",
    "\n",
    "\n",
    "## Learning Objectives:\n",
    "* Linking Phone sensors with Python using OSC protocol\n",
    "* Implement an interactive application based on smartphone input\n",
    "* Save/load datasets\n",
    "\n",
    "---\n",
    "## OSC Protocol\n",
    "\n",
    "OSC (Open Sound Control) was originally developed to control sound devices and instruments over network. For example, an application on your tablet can contain the controllers of an audio synthesiser. It basically sends messages with parameters over network from one device/application to another. For example, message to control volume can be like:\n",
    "<br>__/volume 35__ or __/bgm/volum 35__\n",
    "\n",
    "The first part __/volume__ is the message path, and the following __35__ is the parameter.\n",
    "\n",
    "<br>One main advantage of this protocol is its simplicity and ease to add more messages into it. One downside of it is it can't handle large amount of data in its argument (for example sending large size images).\n",
    "\n",
    "<br>We will/were use this protocol to communicate Python scripts with other applications (for example, Processing). This session we will use it to communicate with smartphone to receive phone's sensors.\n",
    "\n",
    "---\n",
    "## Communicating Smartphone Sensors \n",
    "\n",
    "We will use [Zig-Project](https://zig-project.com) applications to handle sensor data from the phone. __ZIGSIM__ app sends OSC messages to the PC containing selected sensors from the application.\n",
    "\n",
    "<img src=\"./Images/ZIG_1.PNG\" width=\"30%\">\n",
    "\n",
    "You can enable/disable any of the listed sensors in this app. Also, when you hit run button in middle, you can see what data are sent:\n",
    "<img src=\"./Images/ZIG_3.PNG\" width=\"30%\">\n",
    "\n",
    "There is also a useful application for PC named __ZIG indicator__ that can visualize the sent information:\n",
    "<img src=\"./Images/ZIG_4.png\" width=\"80%\">\n",
    "\n",
    "To use ZIG Sim with the Indicator, you will need to configure the Phone app settings:\n",
    "<img src=\"./Images/ZIG_5.PNG\" width=\"30%\">\n",
    "\n",
    "__Protocol__ should be UDP. \n",
    "<br>__IP Address, Port__ should be equal to what the indicator displays. \n",
    "<br>__Message Format__ it should be JSON just for now. \n",
    "<br>__Device UUID__ to your name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Codes\n",
    "\n",
    "* [ZIGSim Input](./Processing/ZIGSim/ZigSim_Input/ZigSim_Input.pde) This program communicates with ZIGSim app running on your phone, and collects the sensors according to what is registered in oscEvent() function. __Make sure to change DeviceUUID variable to your DEVICE UUID in ZIGSIM__. Also, __Set FeaturesCount Variable__ to the number of numbers collected from the sensors. For example:\n",
    " - __accel__: has 3 features\n",
    " - __miclevel__: has 2 features\n",
    "<br> If you want to use both sensors, then you will have 5 features in total.\n",
    " \n",
    " \n",
    "* [ZIGSim Offline Dataset](./Processing/ZIGSim/ZigSim_offlineDataset/ZigSim_offlineDataset.pde): This app, similar to the one above, communicates with ZIGSim to collect sensor data and saves them to dataset files (CSV). This app also requires to set the number of features __FeaturesCount__ and device UUID __DeviceUUID__. Using this sample, you can set number of labels to be trained __Labels__. When pressing (1~9) you can set the label to collect data for. Press Space key to start/stop recording. Pressing S key to save CSV files to data folder.\n",
    "\n",
    "\n",
    "* [Load Table Dataset](./Processing/ZIGSim/loadTableDataset/loadTableDataset.pde): This app loads pre-recoded data and lets you to send them to Wekinator for training. After training you can then use __ZIGSim Input__ app for prediction\n",
    "\n",
    "\n",
    "* [DisplayResult](./Processing/ZIGSim/DisplayResult/DisplayResult.pde): This app shows how to visualize the prediction using images based on the predicted label.\n",
    "\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacing with Arduino \n",
    "\n",
    "Arduino, or almost any other physical computing device (raspberry pi, ESP32, bbc:microbit, ...etc) are very useful to use for custom sensors and low cost/IoT based device. They can accept variety of sensors and thus are very useful for creating \"smart objects\". In order to interface them with Processing, the arduino program should output the sensor values using __Serial Port__. \n",
    "\n",
    "* [ArduinoSendRecv](./Arduino/ArduinoSendRecv/): Contains a sample program for sending and receiving data from python. Can be a very useful program for interfacing arduino with desktop app.\n",
    "<br>\n",
    "\n",
    "* [OSCArduinoSendRecv](./Arduino/OSCArduinoSendRecv/): Sends arduino sensor data to wekinator.\n",
    "<br>\n",
    "\n",
    "* [OSCSensorsTemporal](./Arduino/OSCSensorsTemporal/): Use \"Time\" as temporal factor for designing time based interactions.\n",
    "<br>\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runway ML:\n",
    "\n",
    "Runway is a framework designed to ease the use of existing ML framework to immediately apply and use their inference in an application. It is very usedul for getting more data depending on the problem at hand.\n",
    "\n",
    "* [OSCFaceLandmarks](.\\RunwayML\\OSCFaceLandmarks\\): uses Face-Landmarks model to extract facial landmarks, and passes them to Processing. It can then be used with Wekinator for applied ML.\n",
    "<br>\n",
    "\n",
    "* [ObjectRecognizer](.\\RunwayML\\ObjectRecognizer\\): uses COCO-SSD model to recognize several objetcs in an image. It provides both the extracted labels of the objects (person, table, hourse, phone, ...etc) as well as the bounding box of the object in the image.\n",
    "<br>\n",
    "\n",
    "* [OSCPoseNet](.\\RunwayML\\OSCPoseNet\\): uses PoseNet model to extract the skelton of a person in an image (head, hands, shoulder, legs, torso,..). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
